{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(sentence):\n",
    "\n",
    "    \"Remoção de Emojis nas mensagens de texto.\"\n",
    "\n",
    "    # Padrões dos Emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                u\"\\U00002702-\\U000027B0\"\n",
    "                u\"\\U000024C2-\\U0001F251\"\n",
    "                u\"\\U0001f926-\\U0001f937\"\n",
    "                u'\\U00010000-\\U0010ffff'\n",
    "                u\"\\u200d\"\n",
    "                u\"\\u2640-\\u2642\"\n",
    "                u\"\\u2600-\\u2B55\"\n",
    "                u\"\\u23cf\"\n",
    "                u\"\\u23e9\"\n",
    "                u\"\\u231a\"\n",
    "                u\"\\u3030\"\n",
    "                u\"\\ufe0f\"\n",
    "    \"]+\", flags=re.UNICODE)\n",
    "\n",
    "    return emoji_pattern.sub(r'', sentence)\n",
    "\n",
    "def remove_msgs(sentence):\n",
    "    \n",
    "    new_sentece = ''\n",
    "    \n",
    "    for token in sentence.split():\n",
    "        \n",
    "        # Remover prováveis tokens inúteis\n",
    "        if len(token) > 12:\n",
    "            token = ''\n",
    "    \n",
    "        # Remover Links\n",
    "        if token.startswith('http'):\n",
    "            token = ''\n",
    "            \n",
    "         # Remover Menções, Hashtags e Pontuações\n",
    "        if token.startswith('@') or token.startswith('#'):\n",
    "            token = ''\n",
    "    \n",
    "        new_sentece += ' {}'.format(token)\n",
    "        \n",
    "    return new_sentece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bak_tweets.txt\n",
      "beckasso_tweets.txt\n",
      "bek_tweets.txt\n",
      "belego_tweets.txt\n",
      "belengo_tweets.txt\n",
      "bola_tweets.txt\n",
      "bomba_tweets.txt\n",
      "braw_tweets.txt\n",
      "doce_tweets.txt\n",
      "fina_tweets.txt\n",
      "finex_tweets.txt\n",
      "fumos_tweets.txt\n",
      "marron_tweets.txt\n",
      "mdzin_tweets.txt\n",
      "pamsin_tweets.txt\n",
      "pam_tweets.txt\n",
      "rachice_tweets.txt\n",
      "seda_tweets.txt\n",
      "verdim_tweets.txt\n",
      "verdinha_tweets.txt\n",
      "Elapsed Time: 0.8307859897613525\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    INPUT_DIR = '../data/results/'\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Abrir Arquivos em Formato CSV (.csv)\n",
    "    for filename in os.listdir(INPUT_DIR):\n",
    "        if filename.endswith('.txt'):\n",
    "            \n",
    "            print (filename)\n",
    "\n",
    "            # Abrir cada extração individualmente\n",
    "            df = pd.read_csv(INPUT_DIR + filename, encoding='utf8', names=['Id', 'Message'])\n",
    "\n",
    "            ## Aplicação de Funções ##\n",
    "            \n",
    "            # Remover menções, hashtags e links externos\n",
    "            df['Message'] = df['Message'].map(lambda s: remove_msgs(s))\n",
    "        \n",
    "            # Transformar em String e Letras Minúsculas nas Mensagens\n",
    "            df['Message'] = df['Message'].map(lambda s: str(s).lower())\n",
    "\n",
    "            # Remover Pontuações\n",
    "            df['Message'] = df['Message'].map(lambda s: s.translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "            # Remover Emojis     \n",
    "            df['Message'] = df['Message'].map(lambda s: remove_emojis(s))\n",
    "\n",
    "            # Quebras de Linha desnecessárias\n",
    "            df['Message'] = df['Message'].map(lambda s: s.replace('\\n', ' '))\n",
    "            \n",
    "            # Remover aspas duplas\n",
    "            df['Message'] = df['Message'].map(lambda s: s.replace('\\\"', ''))\n",
    "\n",
    "            # Letras Espaços desnecessários\n",
    "            df['Message'] = df['Message'].map(lambda s: s.strip())\n",
    "\n",
    "            filename = filename.replace('.txt', '')\n",
    "\n",
    "            # Salva o DataFrame em formato CSV\n",
    "            df.to_csv(r'../data/results_processados/{}_processado.csv'.format(filename), index=False, header=True, encoding='utf8')\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print ('Elapsed Time: {}'.format(end_time - start_time))\n",
    "\n",
    "    print ('End')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
